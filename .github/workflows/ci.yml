name: CI

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]
  workflow_dispatch:

jobs:
  # Test across Python versions with CPU-compatible frameworks
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
        os: [ubuntu-latest, windows-latest, macos-latest]
        framework: [none, torch]
        exclude:
          # Reduce matrix size - test torch mainly on ubuntu
          - os: windows-latest
            framework: torch
          - os: macos-latest
            framework: torch

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install base dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Install PyTorch (CPU-only)
        if: matrix.framework == 'torch'
        run: |
          pip install torch --index-url https://download.pytorch.org/whl/cpu

      - name: Run tests with coverage
        run: |
          pytest --cov=arraybridge --cov-report=xml --cov-report=html --cov-report=term-missing -v

      - name: Upload coverage to Codecov
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.12' && matrix.framework == 'torch'
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          fail_ci_if_error: false

  # GPU tests with GitHub Actions GPU runners (optional, non-blocking)
  # Note: GPU runners may have long queue times, so this job is allowed to fail
  gpu-test:
    runs-on: ubuntu-latest-gpu-t4
    continue-on-error: true  # Don't block PR merges if GPU tests fail or timeout
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Check CUDA availability
        run: |
          nvidia-smi
          nvcc --version || echo "NVCC not available"

      - name: Install base dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Install GPU frameworks
        run: |
          # Install PyTorch with CUDA support
          pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
          
          # Install CuPy with CUDA 12.x support
          pip install cupy-cuda12x
          
          # Verify installations
          python -c "import torch; print(f'PyTorch version: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"
          python -c "import cupy as cp; print(f'CuPy version: {cp.__version__}'); print(f'CUDA device: {cp.cuda.Device()}')"

      - name: Run GPU tests
        run: |
          # Run all tests - GPU frameworks will be used when available
          pytest -v --tb=short
          
      - name: Test GPU memory conversions
        run: |
          # Quick sanity check for GPU conversions
          python -c "
          import numpy as np
          import torch
          import cupy as cp
          from arraybridge import convert_memory, detect_memory_type
          
          # Test NumPy -> CuPy
          np_arr = np.array([1, 2, 3], dtype=np.float32)
          cp_arr = convert_memory(np_arr, 'numpy', 'cupy', gpu_id=0)
          print(f'NumPy -> CuPy: {type(cp_arr)}, device: {cp_arr.device}')
          
          # Test NumPy -> PyTorch GPU
          torch_arr = convert_memory(np_arr, 'numpy', 'torch', gpu_id=0)
          print(f'NumPy -> PyTorch: {type(torch_arr)}, device: {torch_arr.device}')
          
          # Test CuPy -> PyTorch
          torch_from_cp = convert_memory(cp_arr, 'cupy', 'torch', gpu_id=0)
          print(f'CuPy -> PyTorch: {type(torch_from_cp)}, device: {torch_from_cp.device}')
          
          print('âœ“ All GPU conversions successful!')
          "

  # Code quality checks
  code-quality:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ruff black mypy

      - name: Run ruff (linting)
        run: |
          ruff check src/ --output-format=github

      - name: Run black (formatting check)
        run: |
          black --check src/

      - name: Run mypy (type checking)
        continue-on-error: true  # Scientific code often has complex types
        run: |
          mypy src/ --ignore-missing-imports
